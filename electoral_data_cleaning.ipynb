{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"electoral2015_tour1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_title_unicode = data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### We see that the data is in Unicode format, which will cause some trouble later. We will try to convert it to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def unicode_to_string(word):\n",
    "    if pd.isnull(word):\n",
    "        return \n",
    "    else:\n",
    "        return unicodedata.normalize('NFKD', word).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_title = map(unicode_to_string,col_title_unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We replace the column head by new string-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.columns = col_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Date de l'export\",\n",
       " 'Code du departement',\n",
       " 'Libelle du departement',\n",
       " 'Code de la commune',\n",
       " 'Libelle de la commune',\n",
       " 'Inscrits',\n",
       " 'Abstentions',\n",
       " '% Abs/Ins',\n",
       " 'Votants',\n",
       " '% Vot/Ins',\n",
       " 'Blancs',\n",
       " '% Blancs/Ins',\n",
       " '% Blancs/Vot',\n",
       " 'Nuls',\n",
       " '% Nuls/Ins',\n",
       " '% Nuls/Vot',\n",
       " 'Exprimes',\n",
       " '% Exp/Ins',\n",
       " '% Exp/Vot',\n",
       " 'NListe',\n",
       " 'Nuance Liste',\n",
       " 'Libelle Abrege Liste',\n",
       " 'Libelle Etendu Liste',\n",
       " 'Nom Tete de Liste',\n",
       " 'Voix',\n",
       " '% Voix/Ins',\n",
       " '% Voix/Exp',\n",
       " 'NListe.1',\n",
       " 'Nuance Liste.1',\n",
       " 'Libelle Abrege Liste.1',\n",
       " 'Libelle Etendu Liste.1',\n",
       " 'Nom Tete de Liste.1',\n",
       " 'Voix.1',\n",
       " '% Voix/Ins.1',\n",
       " '% Voix/Exp.1',\n",
       " 'NListe.2',\n",
       " 'Nuance Liste.2',\n",
       " 'Libelle Abrege Liste.2',\n",
       " 'Libelle Etendu Liste.2',\n",
       " 'Nom Tete de Liste.2',\n",
       " 'Voix.2',\n",
       " '% Voix/Ins.2',\n",
       " '% Voix/Exp.2',\n",
       " 'NListe.3',\n",
       " 'Nuance Liste.3',\n",
       " 'Libelle Abrege Liste.3',\n",
       " 'Libelle Etendu Liste.3',\n",
       " 'Nom Tete de Liste.3',\n",
       " 'Voix.3',\n",
       " '% Voix/Ins.3',\n",
       " '% Voix/Exp.3',\n",
       " 'NListe.4',\n",
       " 'Nuance Liste.4',\n",
       " 'Libelle Abrege Liste.4',\n",
       " 'Libelle Etendu Liste.4',\n",
       " 'Nom Tete de Liste.4',\n",
       " 'Voix.4',\n",
       " '% Voix/Ins.4',\n",
       " '% Voix/Exp.4',\n",
       " 'NListe.5',\n",
       " 'Nuance Liste.5',\n",
       " 'Libelle Abrege Liste.5',\n",
       " 'Libelle Etendu Liste.5',\n",
       " 'Nom Tete de Liste.5',\n",
       " 'Voix.5',\n",
       " '% Voix/Ins.5',\n",
       " '% Voix/Exp.5',\n",
       " 'NListe.6',\n",
       " 'Nuance Liste.6',\n",
       " 'Libelle Abrege Liste.6',\n",
       " 'Libelle Etendu Liste.6',\n",
       " 'Nom Tete de Liste.6',\n",
       " 'Voix.6',\n",
       " '% Voix/Ins.6',\n",
       " '% Voix/Exp.6',\n",
       " 'NListe.7',\n",
       " 'Nuance Liste.7',\n",
       " 'Libelle Abrege Liste.7',\n",
       " 'Libelle Etendu Liste.7',\n",
       " 'Nom Tete de Liste.7',\n",
       " 'Voix.7',\n",
       " '% Voix/Ins.7',\n",
       " '% Voix/Exp.7',\n",
       " 'NListe.8',\n",
       " 'Nuance Liste.8',\n",
       " 'Libelle Abrege Liste.8',\n",
       " 'Libelle Etendu Liste.8',\n",
       " 'Nom Tete de Liste.8',\n",
       " 'Voix.8',\n",
       " '% Voix/Ins.8',\n",
       " '% Voix/Exp.8',\n",
       " 'NListe.9',\n",
       " 'Nuance Liste.9',\n",
       " 'Libelle Abrege Liste.9',\n",
       " 'Libelle Etendu Liste.9',\n",
       " 'Nom Tete de Liste.9',\n",
       " 'Voix.9',\n",
       " '% Voix/Ins.9',\n",
       " '% Voix/Exp.9',\n",
       " 'NListe.10',\n",
       " 'Nuance Liste.10',\n",
       " 'Libelle Abrege Liste.10',\n",
       " 'Libelle Etendu Liste.10',\n",
       " 'Nom Tete de Liste.10',\n",
       " 'Voix.10',\n",
       " '% Voix/Ins.10',\n",
       " '% Voix/Exp.10',\n",
       " 'NListe.11',\n",
       " 'Nuance Liste.11',\n",
       " 'Libelle Abrege Liste.11',\n",
       " 'Libelle Etendu Liste.11',\n",
       " 'Nom Tete de Liste.11',\n",
       " 'Voix.11',\n",
       " '% Voix/Ins.11',\n",
       " '% Voix/Exp.11',\n",
       " 'NListe.12',\n",
       " 'Nuance Liste.12',\n",
       " 'Libelle Abrege Liste.12',\n",
       " 'Libelle Etendu Liste.12',\n",
       " 'Nom Tete de Liste.12',\n",
       " 'Voix.12',\n",
       " '% Voix/Ins.12',\n",
       " '% Voix/Exp.12']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We see that not only the column header but all the text-format cells in the dataset are in unicode. We will now convert all to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_to_string(data):\n",
    "    new_data = data.copy()\n",
    "    for col in new_data.columns:\n",
    "        not_nan_index = [not ind for ind in new_data[col].isnull()]\n",
    "        not_nan_value = new_data[col][not_nan_index]\n",
    "        if type(not_nan_value.iloc[0]) == unicode: #check the first not-NaN value\n",
    "            new_data[col] = map(unicode_to_string,new_data[col])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data_to_string(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are NaN values in Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan_in_numeric(data):\n",
    "    new_data = data.copy()\n",
    "    for col in new_data.columns:\n",
    "        not_nan_index = [not ind for ind in new_data[col].isnull()]\n",
    "        not_nan_value = new_data[col][not_nan_index]\n",
    "        if type(not_nan_value.iloc[0]) is not str : #check the first not-NaN value to eliminate all string column\n",
    "            if new_data[col].isnull().any(): \n",
    "                print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NListe.8\n",
      "Voix.8\n",
      "% Voix/Ins.8\n",
      "% Voix/Exp.8\n",
      "NListe.9\n",
      "Voix.9\n",
      "% Voix/Ins.9\n",
      "% Voix/Exp.9\n",
      "NListe.10\n",
      "Voix.10\n",
      "% Voix/Ins.10\n",
      "% Voix/Exp.10\n",
      "NListe.11\n",
      "Voix.11\n",
      "% Voix/Ins.11\n",
      "% Voix/Exp.11\n",
      "NListe.12\n",
      "Voix.12\n",
      "% Voix/Ins.12\n",
      "% Voix/Exp.12\n"
     ]
    }
   ],
   "source": [
    "check_nan_in_numeric(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem here is that the number of parties is not the same in all communities: most of them have 8 parties, but some of them have more than 8. \n",
    "### Therefore, before checking for NaN value, we need to re-organize the data.\n",
    "### We will create a new dataframe that has only 1 voting result per row.\n",
    "### We start by adding a new column in the original dataset: Code Insee. We will use this as our pivot column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_insee_code(data):\n",
    "    new_data = data.copy()\n",
    "    insee_code = []\n",
    "    for x in xrange(len(new_data)):\n",
    "        if new_data['Code du departement'][x] < 100:\n",
    "            code = new_data['Code du departement'][x]*1000 + new_data['Code de la commune'][x]\n",
    "        else:\n",
    "            code = (new_data['Code du departement'][x]/10)*1000 + new_data['Code de la commune'][x]\n",
    "        insee_code.append(code)\n",
    "    new_data['Code Insee'] = insee_code\n",
    "    cols = new_data.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1] # we move the new variable to the first column of our dataframe\n",
    "    new_data = new_data[cols]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = add_insee_code(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (NB: we had to manually modify some departement codes like those of Corse, Reunion, Martinique,.... because they were not in numerical form)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create the new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nan(data):\n",
    "    new_data = data.copy()\n",
    "    boolean_df = pd.notnull(new_data[new_data.columns.tolist()[1:]])\n",
    "    boolean_list = [any(row) for index, row in boolean_df.iterrows()]\n",
    "    new_data = new_data[boolean_list]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_voting_data(data):\n",
    "    data_index = ['Code Insee', 'NListe', 'Nuance Liste', 'Voix', '% Voix/Ins','% Voix/Exp']\n",
    "\n",
    "    code_insee = 'Code Insee'\n",
    "    nListe = 'NListe'\n",
    "    nuance_liste = 'Nuance Liste'\n",
    "    voix = 'Voix'\n",
    "    voix_ins = '% Voix/Ins'\n",
    "    voix_exp = '% Voix/Exp'\n",
    "\n",
    "    voting_data = data[data_index] \n",
    "    counter = 1\n",
    "\n",
    "    while True:\n",
    "        new_nListe = nListe + '.' + str(counter)\n",
    "        new_nuance_liste = nuance_liste + '.' + str(counter)\n",
    "        new_voix = voix + '.' + str(counter)\n",
    "        new_voix_ins = voix_ins + '.' + str(counter)\n",
    "        new_voix_exp = voix_exp + '.' + str(counter)\n",
    "\n",
    "        try: # condition to stop\n",
    "            data[new_nListe] \n",
    "        except: \n",
    "            break\n",
    "\n",
    "        new_data_index = ['Code Insee',new_nListe,new_nuance_liste, new_voix,new_voix_ins, new_voix_exp]\n",
    "        new_data = data[new_data_index]\n",
    "        new_data.columns = data_index\n",
    "        voting_data = pd.concat([voting_data, new_data])\n",
    "        counter += 1\n",
    "\n",
    "    voting_data = remove_nan(voting_data)\n",
    "    voting_data = voting_data.sort_index() \n",
    "    voting_data.index = range(0,len(voting_data))\n",
    "    \n",
    "    return voting_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voting_data = create_voting_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have a clean list, we will divide it into 3 groups corresponding to the 3 political orienatations: Left, Right and Extreme Right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LDVG',\n",
       " 'LDVD',\n",
       " 'LECO',\n",
       " 'LDLF',\n",
       " 'LCOM',\n",
       " 'LUDI',\n",
       " 'LDIV',\n",
       " 'LFN',\n",
       " 'LFG',\n",
       " 'LEXD',\n",
       " 'LEXG',\n",
       " 'LUD',\n",
       " 'LREG',\n",
       " 'LUG',\n",
       " 'LSOC',\n",
       " 'LVEG',\n",
       " 'LMDM',\n",
       " 'LRDG',\n",
       " 'LLR',\n",
       " 'LVEC']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(voting_data['Nuance Liste']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_party = ['LDVG', 'LCOM', 'LFG', 'LEXG','LSOC','LVEG','LREG','LUG']\n",
    "right_party = ['LDVD','LDLF', 'LUDI','LUD','LMDM', 'LRDG','LLR'] \n",
    "er_party = ['LFN','LEXD',] \n",
    "other_party = ['LECO','LDIV', 'LVEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left_party_vote = voting_data[voting_data['Nuance Liste'].isin(left_party)]\n",
    "left_party_vote.index = range(0, len(left_party_vote))\n",
    "                              \n",
    "right_party_vote = voting_data[voting_data['Nuance Liste'].isin(right_party)]\n",
    "right_party_vote.index = range(0, len(right_party_vote))\n",
    "                               \n",
    "er_party_vote = voting_data[voting_data['Nuance Liste'].isin(er_party)]\n",
    "er_party_vote.index = range(0, len(er_party_vote))\n",
    "                            \n",
    "other_party_vote = voting_data[voting_data['Nuance Liste'].isin(other_party)]\n",
    "other_party_vote.index = range(0, len(other_party_vote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We export these dataframes to excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('left_party_vote.xlsx')\n",
    "left_party_vote.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('right_party_vote.xlsx')\n",
    "right_party_vote.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('er_party_vote.xlsx')\n",
    "er_party_vote.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
