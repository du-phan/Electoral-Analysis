{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script have all functions to clean and export the voting result of each parties (left, right or extreme right) for the regional electoral data. \n",
    "### The main function is clean_data(data), it will do the following tasks: \n",
    "        * Import data.\n",
    "        * Convert unicode to string.\n",
    "        * Convert non-numerical departmental code to numerical.\n",
    "        * Add Insee code.\n",
    "        * Filter list for voting data. \n",
    "        * Group voting data by political parties (left/right/er).\n",
    "        * Export data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------- FUNCTIONS THAT WE WILL NEED -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Â We see that the data is in Unicode format, which will cause some trouble later. We will try to convert it to string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def unicode_to_string(word):\n",
    "    if word == False: # there are some town that are named Faux, which confused the program \n",
    "        word = u'Faux'\n",
    "    if pd.isnull(word):\n",
    "        return \n",
    "    else:\n",
    "        return unicodedata.normalize('NFKD', word).encode('ascii','ignore')\n",
    "    \n",
    "def data_to_string(data):\n",
    "    new_data = data.copy()\n",
    "    \n",
    "    col_title_unicode = new_data.columns.values.tolist()\n",
    "    col_title = map(unicode_to_string,col_title_unicode)\n",
    "    new_data.columns = col_title\n",
    "    \n",
    "    for col in new_data.columns:\n",
    "        not_nan_index = [not ind for ind in new_data[col].isnull()]\n",
    "        not_nan_value = new_data[col][not_nan_index]\n",
    "        if type(not_nan_value.iloc[0]) == unicode: #check the first not-NaN value\n",
    "            new_data[col] = map(unicode_to_string,new_data[col]) \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are NaN values in Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_nan_in_numeric(data):\n",
    "    new_data = data.copy()\n",
    "    for col in new_data.columns:\n",
    "        not_nan_index = [not ind for ind in new_data[col].isnull()]\n",
    "        not_nan_value = new_data[col][not_nan_index]\n",
    "        if type(not_nan_value.iloc[0]) is not str : #check the first not-NaN value to eliminate all string column\n",
    "            if new_data[col].isnull().any(): \n",
    "                print col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem here is that the number of parties is not the same in all communities: most of them have 8 parties, but some of them have more than 8. \n",
    "### Therefore, before checking for NaN value, we need to re-organize the data.\n",
    "### We will create a new dataframe that has only 1 voting result per row.\n",
    "### We start by adding a new column in the original dataset: Code Insee. We will use this as our pivot column.\n",
    "### Before we can add the Insee Code. We need to modify some department codes like those of Corse, Reunion, Martinique,.. because they are not in numerical form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_departmental_code(data):\n",
    "    new_data = data.copy()\n",
    "    code_list = {'la reunion':974, 'guyane':973, 'martinique':972, 'guadeloupe':971, 'corse':20}\n",
    "    for departement in code_list.keys(): \n",
    "        index = data['Libelle du departement'].str.lower().str.contains(departement)\n",
    "        new_data.loc[index,'Code du departement'] = code_list[departement]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_insee_code(data):\n",
    "    new_data = data.copy()\n",
    "    insee_code = []\n",
    "    for x in xrange(len(new_data)):\n",
    "        if new_data['Code du departement'][x] < 100:\n",
    "            code = new_data['Code du departement'][x]*1000 + new_data['Code de la commune'][x]\n",
    "        else:\n",
    "            code = (new_data['Code du departement'][x]/10)*1000 + new_data['Code de la commune'][x]\n",
    "        insee_code.append(code)\n",
    "    new_data['Code Insee'] = insee_code\n",
    "    cols = new_data.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1] # we move the new variable to the first column of our dataframe\n",
    "    new_data = new_data[cols]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create the new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_nan(data):\n",
    "    new_data = data.copy()\n",
    "    boolean_df = pd.notnull(new_data[new_data.columns.tolist()[1:]])\n",
    "    boolean_list = [any(row) for index, row in boolean_df.iterrows()]\n",
    "    new_data = new_data[boolean_list]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_voting_data(data):\n",
    "    data_index = ['Code Insee', 'Nuance Liste','% Voix/Exp']\n",
    "\n",
    "    code_insee = 'Code Insee'\n",
    "    #nListe = 'NListe'\n",
    "    nuance_liste = 'Nuance Liste'\n",
    "    #voix = 'Voix'\n",
    "    #voix_ins = '% Voix/Ins'\n",
    "    voix_exp = '% Voix/Exp'\n",
    "\n",
    "    voting_data = data[data_index] \n",
    "    counter = 1\n",
    "\n",
    "    while True:\n",
    "        #new_nListe = nListe + '.' + str(counter)\n",
    "        new_nuance_liste = nuance_liste + '.' + str(counter)\n",
    "        #new_voix = voix + '.' + str(counter)\n",
    "        #new_voix_ins = voix_ins + '.' + str(counter)\n",
    "        new_voix_exp = voix_exp + '.' + str(counter)\n",
    "\n",
    "        try: # condition to stop\n",
    "            data[new_nuance_liste]  \n",
    "        except: \n",
    "            break\n",
    "\n",
    "        new_data_index = ['Code Insee',new_nuance_liste, new_voix_exp]\n",
    "        new_data = data[new_data_index]\n",
    "        new_data.columns = data_index\n",
    "        voting_data = pd.concat([voting_data, new_data])\n",
    "        counter += 1\n",
    "\n",
    "    voting_data = remove_nan(voting_data) # we remove all the empty rows \n",
    "    voting_data = voting_data.sort_index() \n",
    "    voting_data.index = range(0,len(voting_data))\n",
    "    \n",
    "    return voting_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once we have a clean list, we will divide it into 3 groups corresponding to the 3 political orienatations: Left, Right and Extreme Right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_party = ['LDVG', 'LCOM', 'LFG', 'LEXG','LSOC','LVEG','LREG','LUG','LCOP','LXG','LDG']\n",
    "right_party = ['LDVD','LDLF', 'LUDI','LUD','LMDM', 'LRDG','LLR', 'LAUT','LDR', 'LDD'] \n",
    "er_party = ['LFN','LEXD','LXD'] \n",
    "other_party = ['LECO','LDIV', 'LVEC', 'LMAJ', 'LCMD', 'LDV','LGA','LVE','LEC','LCP','LRG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we group all the result of the right/left party in each town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupby_town(data, original_data):\n",
    "    new_data = data.copy()\n",
    "    #new_data = new_data.drop(['NListe','Nuance Liste'],1)\n",
    "    new_data = new_data.groupby('Code Insee')\n",
    "    new_data = new_data.aggregate(np.sum).reset_index() # we sum all the votes of right/left/er lists in 1 town\n",
    "    #abs_ins = original_data[['Code Insee','% Abs/Ins']] # we add abstention information\n",
    "    #new_data = pd.merge(new_data,abs_ins, on = 'Code Insee',how='left')\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------- MAIN FUNCTION -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(file, export_name):\n",
    "    data = pd.read_excel(file)\n",
    "    data = data_to_string(data)\n",
    "    data = convert_departmental_code(data)\n",
    "    data = add_insee_code(data)\n",
    "    voting_data = create_voting_data(data)\n",
    "    \n",
    "    left_party = ['LDVG', 'LCOM', 'LFG', 'LEXG','LSOC','LVEG','LREG','LUG','LCOP','LXG','LDG']\n",
    "    right_party = ['LDVD','LDLF', 'LUDI','LUD','LMDM', 'LRDG','LLR', 'LAUT','LDR', 'LDD'] \n",
    "    er_party = ['LFN','LEXD','LXD'] \n",
    "    other_party = ['LECO','LDIV', 'LVEC', 'LMAJ', 'LCMD', 'LDV','LGA','LVE','LEC','LCP','LRG']\n",
    "    \n",
    "    left_party_vote = voting_data[voting_data['Nuance Liste'].isin(left_party)]\n",
    "    left_party_vote.index = range(0, len(left_party_vote))\n",
    "\n",
    "    right_party_vote = voting_data[voting_data['Nuance Liste'].isin(right_party)]\n",
    "    right_party_vote.index = range(0, len(right_party_vote))\n",
    "\n",
    "    er_party_vote = voting_data[voting_data['Nuance Liste'].isin(er_party)]\n",
    "    er_party_vote.index = range(0, len(er_party_vote))\n",
    "\n",
    "    other_party_vote = voting_data[voting_data['Nuance Liste'].isin(other_party)]\n",
    "    other_party_vote.index = range(0, len(other_party_vote))\n",
    "    \n",
    "    left_party_vote = groupby_town(left_party_vote,data) \n",
    "    right_party_vote = groupby_town(right_party_vote,data)\n",
    "    er_party_vote = groupby_town(er_party_vote,data)\n",
    "    other_party_vote = groupby_town(other_party_vote,data)\n",
    "    \n",
    "    left_party_vote.columns = ['Code Insee', export_name+' vote']\n",
    "    right_party_vote.columns = ['Code Insee', export_name+' vote']\n",
    "    er_party_vote.columns = ['Code Insee', export_name+' vote']\n",
    "    \n",
    "    writer1 = pd.ExcelWriter('cleaned_data/'+export_name+'_right.xlsx')\n",
    "    left_party_vote.to_excel(writer1,'Sheet1')\n",
    "    writer1.save()\n",
    "    \n",
    "    writer2 = pd.ExcelWriter('cleaned_data/'+export_name+'_left.xlsx')\n",
    "    right_party_vote.to_excel(writer2,'Sheet1')\n",
    "    writer2.save()\n",
    "    \n",
    "    writer3 = pd.ExcelWriter('cleaned_data/'+export_name+'_er.xlsx')\n",
    "    er_party_vote.to_excel(writer3,'Sheet1')\n",
    "    writer3.save()\n",
    "    \n",
    "    return left_party_vote, right_party_vote, er_party_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "left,right,er = clean_data(file='original_data/regionale2015.xlsx', export_name='regionale2015')\n",
    "left,right,er = clean_data(file='original_data/regionale2010.xls', export_name='regionale2010')\n",
    "left,right,er = clean_data(file='original_data/regionale2004.xls', export_name='regionale2004')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "#cProfile.run(\"clean_data('regionale2015.xlsx','regionale2015')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
